{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### installations"
      ],
      "metadata": {
        "id": "vn4ayoZVAJAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 1. Install Dependencies\n",
        "!pip install torch charformer-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqlD_THxth2k",
        "outputId": "4afd0e0a-0e87-4844-dc10-874d32dc369f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting charformer-pytorch\n",
            "  Downloading charformer_pytorch-0.0.4-py3-none-any.whl.metadata (655 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: einops>=0.3 in /usr/local/lib/python3.12/dist-packages (from charformer-pytorch) (0.8.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading charformer_pytorch-0.0.4-py3-none-any.whl (4.8 kB)\n",
            "Installing collected packages: charformer-pytorch\n",
            "Successfully installed charformer-pytorch-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install libinjection-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NSJ7hVnAGGw",
        "outputId": "7dc4c5e5-e3f2-4217-a836-bbfa4a079671"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting libinjection-python\n",
            "  Downloading libinjection-python-1.1.6.tar.gz (174 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/174.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.0/174.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: libinjection-python\n",
            "  Building wheel for libinjection-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libinjection-python: filename=libinjection_python-1.1.6-cp312-cp312-linux_x86_64.whl size=251706 sha256=b4ebc3bba7a9dc748bb1b8bc92b5ad841afca5e57e7b24ddeb693b3ce48d39a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/a2/0f/eb48da355b19a32635f793215e5d5908b072f7dc951e9fe295\n",
            "Successfully built libinjection-python\n",
            "Installing collected packages: libinjection-python\n",
            "Successfully installed libinjection-python-1.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### injection model detector"
      ],
      "metadata": {
        "id": "3RZ4jk8_tn2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Dict, List, Optional\n",
        "import warnings\n",
        "from charformer_pytorch import GBST\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "k81gSh5F64ni"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InjectionDetectionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Enhanced model with better regularization\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 num_tokens: int = 257,\n",
        "                 dim: int = 128,\n",
        "                 max_block_size: int = 4,\n",
        "                 score_consensus_attn: bool = True,\n",
        "                 d_model: int = 128,\n",
        "                 nhead: int = 1,\n",
        "                 dim_feedforward: int = 256,\n",
        "                 num_layers: int = 1,\n",
        "                 max_length: int = 2048,\n",
        "                 downsample_factor: int = 4,\n",
        "                 mlp_hidden_dims: List[int] = [256, 128],\n",
        "                 dropout: float = 0.2,  # INCREASED from 0.1 to 0.2\n",
        "                 attack_type: str = \"unknown\"):\n",
        "\n",
        "        super(InjectionDetectionModel, self).__init__()\n",
        "\n",
        "        self.attack_type = attack_type\n",
        "        self.max_length = max_length\n",
        "        self.downsample_factor = downsample_factor\n",
        "        self.d_model = d_model\n",
        "        self.gbst_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "        # GBST architecture (unchanged)\n",
        "        self.gbst = GBST(\n",
        "            num_tokens=num_tokens,\n",
        "            dim=dim,\n",
        "            max_block_size=max_block_size,\n",
        "            score_consensus_attn=score_consensus_attn\n",
        "        )\n",
        "\n",
        "        # Transformer with increased dropout\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,  # Now uses the increased dropout\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Enhanced MLP with Batch Normalization\n",
        "        mlp_layers = []\n",
        "        input_dim = d_model\n",
        "\n",
        "        for hidden_dim in mlp_hidden_dims:\n",
        "            mlp_layers.extend([\n",
        "                nn.Linear(input_dim, hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm1d(hidden_dim),  # ADDED: Batch normalization\n",
        "                nn.Dropout(dropout)\n",
        "            ])\n",
        "            input_dim = hidden_dim\n",
        "\n",
        "        mlp_layers.append(nn.Linear(input_dim, 1))\n",
        "        self.mlp = nn.Sequential(*mlp_layers)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"Forward pass - unchanged logic\"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # GBST Tokenization\n",
        "        gbst_output = self.gbst(x)\n",
        "        if isinstance(gbst_output, tuple):\n",
        "            gbst_output, gbst_mask = gbst_output\n",
        "\n",
        "        gbst_output = self.gbst_norm(gbst_output)\n",
        "\n",
        "        # Transformer Encoder\n",
        "        if attention_mask is not None:\n",
        "            attention_mask = attention_mask[:, ::self.downsample_factor]\n",
        "\n",
        "        encoder_output = self.transformer_encoder(\n",
        "            gbst_output,\n",
        "            src_key_padding_mask=attention_mask if attention_mask is not None else None\n",
        "        )\n",
        "\n",
        "        # Classification with attention masking\n",
        "        if attention_mask is not None:\n",
        "            mask_expanded = (~attention_mask).unsqueeze(-1).expand_as(encoder_output)\n",
        "            encoder_output = encoder_output * mask_expanded.float()\n",
        "            pooled = encoder_output.sum(dim=1) / mask_expanded.sum(dim=1)\n",
        "        else:\n",
        "            pooled = encoder_output.mean(dim=1)\n",
        "\n",
        "        logits = self.mlp(pooled)\n",
        "        probabilities = self.sigmoid(logits)\n",
        "\n",
        "        return {\n",
        "            'logits': logits.squeeze(-1),\n",
        "            'probabilities': probabilities.squeeze(-1),\n",
        "            'encoder_output': encoder_output,\n",
        "            'attention_weights': None\n",
        "        }\n"
      ],
      "metadata": {
        "id": "vqoNMgLl6VZm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiClassInjectionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Transfer learning model for multi-class attack classification\n",
        "    Replaces binary classification head with multi-class head\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_model: nn.Module, num_classes: int = 4, hidden_dim: int = 128):\n",
        "        super(MultiClassInjectionModel, self).__init__()\n",
        "\n",
        "        # Keep original model components\n",
        "        self.gbst = base_model.gbst\n",
        "        self.gbst_norm = base_model.gbst_norm\n",
        "        self.transformer_encoder = base_model.transformer_encoder\n",
        "        self.d_model = base_model.d_model\n",
        "        self.downsample_factor = base_model.downsample_factor\n",
        "\n",
        "        # Replace classification head with multi-class head\n",
        "        self.multi_class_head = nn.Sequential(\n",
        "            nn.Linear(self.d_model, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "        print(f\"Multi-class model created with {num_classes} classes\")\n",
        "\n",
        "    def forward(self, x: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # GBST encoding\n",
        "        gbst_output = self.gbst(x)\n",
        "        if isinstance(gbst_output, tuple):\n",
        "            gbst_output, _ = gbst_output\n",
        "        gbst_output = self.gbst_norm(gbst_output)\n",
        "\n",
        "        # Transformer encoding\n",
        "        if attention_mask is not None:\n",
        "            attention_mask = attention_mask[:, ::self.downsample_factor]\n",
        "\n",
        "        encoder_output = self.transformer_encoder(\n",
        "            gbst_output,\n",
        "            src_key_padding_mask=attention_mask if attention_mask is not None else None\n",
        "        )\n",
        "\n",
        "        # Pooling\n",
        "        if attention_mask is not None:\n",
        "            mask_expanded = (~attention_mask).unsqueeze(-1).expand_as(encoder_output)\n",
        "            encoder_output = encoder_output * mask_expanded.float()\n",
        "            pooled = encoder_output.sum(dim=1) / mask_expanded.sum(dim=1)\n",
        "        else:\n",
        "            pooled = encoder_output.mean(dim=1)\n",
        "\n",
        "        # Multi-class classification\n",
        "        logits = self.multi_class_head(pooled)\n",
        "        probabilities = torch.softmax(logits, dim=-1)\n",
        "\n",
        "        return {\n",
        "            'logits': logits,\n",
        "            'probabilities': probabilities,\n",
        "            'encoder_output': encoder_output\n",
        "        }\n"
      ],
      "metadata": {
        "id": "Mpo9L7iu6q6x"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Production Injection Detection System\n",
        "Provides both binary detection and attack type classification\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class InjectionDetector:\n",
        "    \"\"\"\n",
        "    Production-ready injection detection system\n",
        "\n",
        "    Usage:\n",
        "        detector = InjectionDetector(\n",
        "            binary_model_path='models/binary_model.pth',\n",
        "            multiclass_model_path='models/multiclass_model.pth'\n",
        "        )\n",
        "\n",
        "        result = detector.detect('SELECT * FROM users')\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 binary_model_path: str,\n",
        "                 multiclass_model_path: str,\n",
        "                 device: str = None,\n",
        "                 max_length: int = 2048):\n",
        "        \"\"\"\n",
        "        Initialize detector with trained models\n",
        "\n",
        "        Args:\n",
        "            binary_model_path: Path to binary classification model (.pth)\n",
        "            multiclass_model_path: Path to multi-class model (.pth)\n",
        "            device: 'cuda' or 'cpu'. Auto-detects if None\n",
        "            max_length: Maximum input length (default: 2048)\n",
        "        \"\"\"\n",
        "\n",
        "        if device is None:\n",
        "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        else:\n",
        "            self.device = device\n",
        "\n",
        "        self.max_length = max_length\n",
        "\n",
        "        # Load binary model\n",
        "        print(f\"Loading binary model from {binary_model_path}...\")\n",
        "        #from models import InjectionDetectionModel  # Your model definition\n",
        "        self.binary_model = InjectionDetectionModel()\n",
        "        self.binary_model.load_state_dict(torch.load(binary_model_path, map_location=self.device))\n",
        "        self.binary_model.to(self.device)\n",
        "        self.binary_model.eval()\n",
        "\n",
        "        # Load multi-class model\n",
        "        print(f\"Loading multi-class model from {multiclass_model_path}...\")\n",
        "        #from models import MultiClassInjectionModel\n",
        "        base_model = InjectionDetectionModel()\n",
        "        self.multiclass_model = MultiClassInjectionModel(base_model, num_classes=4)\n",
        "        self.multiclass_model.load_state_dict(torch.load(multiclass_model_path, map_location=self.device))\n",
        "        self.multiclass_model.to(self.device)\n",
        "        self.multiclass_model.eval()\n",
        "\n",
        "        self.attack_types = ['sqli', 'commandi', 'xss', 'traversal']\n",
        "\n",
        "        print(f\"Models loaded successfully on {self.device}\")\n",
        "\n",
        "    def _preprocess(self, text: str) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"Convert text to model input format\"\"\"\n",
        "\n",
        "        # Convert to bytes\n",
        "        byte_sequence = list(text.encode('utf-8'))\n",
        "\n",
        "        if len(byte_sequence) > self.max_length:\n",
        "            byte_sequence = byte_sequence[:self.max_length]\n",
        "\n",
        "        attention_mask = [False] * len(byte_sequence)\n",
        "\n",
        "        while len(byte_sequence) < self.max_length:\n",
        "            byte_sequence.append(0)\n",
        "            attention_mask.append(True)\n",
        "\n",
        "        return {\n",
        "            'input_ids': torch.tensor([byte_sequence], dtype=torch.long).to(self.device),\n",
        "            'attention_mask': torch.tensor([attention_mask], dtype=torch.bool).to(self.device)\n",
        "        }\n",
        "\n",
        "    def detect(self, text: str, threshold: float = 0.5) -> Dict:\n",
        "        \"\"\"\n",
        "        Detect if input contains injection attack\n",
        "\n",
        "        Args:\n",
        "            text: Input text to analyze\n",
        "            threshold: Detection threshold (default: 0.5)\n",
        "\n",
        "        Returns:\n",
        "            Dict with detection results:\n",
        "            {\n",
        "                'is_malicious': bool,\n",
        "                'confidence': float,\n",
        "                'attack_type': str or None,\n",
        "                'attack_confidence': float or None\n",
        "            }\n",
        "        \"\"\"\n",
        "\n",
        "        if not text or not text.strip():\n",
        "            return {\n",
        "                'is_malicious': False,\n",
        "                'confidence': 1.0,\n",
        "                'attack_type': None,\n",
        "                'attack_confidence': None\n",
        "            }\n",
        "\n",
        "        # Preprocess\n",
        "        inputs = self._preprocess(text)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Binary classification\n",
        "            binary_output = self.binary_model(inputs['input_ids'], inputs['attention_mask'])\n",
        "            malicious_prob = binary_output['probabilities'].item()\n",
        "            is_malicious = malicious_prob > threshold\n",
        "\n",
        "            # If malicious, classify attack type\n",
        "            attack_type = None\n",
        "            attack_confidence = None\n",
        "\n",
        "            if is_malicious:\n",
        "                multiclass_output = self.multiclass_model(inputs['input_ids'], inputs['attention_mask'])\n",
        "                probs = multiclass_output['probabilities'][0].cpu().numpy()\n",
        "                attack_idx = probs.argmax()\n",
        "                attack_type = self.attack_types[attack_idx]\n",
        "                attack_confidence = float(probs[attack_idx])\n",
        "\n",
        "        return {\n",
        "            'is_malicious': is_malicious,\n",
        "            'confidence': float(malicious_prob),\n",
        "            'attack_type': attack_type,\n",
        "            'attack_confidence': attack_confidence\n",
        "        }\n",
        "\n",
        "    def batch_detect(self, texts: List[str], threshold: float = 0.5) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Batch detection for multiple texts\n",
        "\n",
        "        Args:\n",
        "            texts: List of texts to analyze\n",
        "            threshold: Detection threshold\n",
        "\n",
        "        Returns:\n",
        "            List of detection results\n",
        "        \"\"\"\n",
        "        return [self.detect(text, threshold) for text in texts]\n"
      ],
      "metadata": {
        "id": "cfrkM6Mrtqc2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize once (expensive operation)\n",
        "detector = InjectionDetector(\n",
        "    binary_model_path='/content/best_binary_injection_model.pth',\n",
        "    multiclass_model_path='/content/best_multiclass_model.pth',\n",
        "    device='cpu'  # 'cuda' or 'cpu'\n",
        ")\n",
        "start_time = time.time()\n",
        "# Single prediction\n",
        "text = \"value=%27test%27\"\n",
        "result = detector.detect(text, threshold=0.5)\n",
        "end_time = time.time()\n",
        "avg_time = (end_time - start_time) / 1000 * 1000  # Convert to milliseconds\n",
        "print(f\"Average processing time: {avg_time:.3f} ms per request\")\n",
        "# Result format:\n",
        "# {\n",
        "#     'is_malicious': True/False,\n",
        "#     'confidence': 0.0-1.0,\n",
        "#     'attack_type': 'sqli'/'xss'/'commandi'/'traversal' or None,\n",
        "#     'attack_confidence': 0.0-1.0 or None\n",
        "# }\n",
        "\n",
        "# Batch prediction\n",
        "texts = [\"text1\", \"text2\", \"text3\"]\n",
        "results = detector.batch_detect(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTS9F7QZyk9c",
        "outputId": "af38ceb9-e487-4d49-8c4d-aca6ef1cc990"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading binary model from /content/best_binary_injection_model.pth...\n",
            "Loading multi-class model from /content/best_multiclass_model.pth...\n",
            "Multi-class model created with 4 classes\n",
            "Models loaded successfully on cpu\n",
            "Average processing time: 0.069 ms per request\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7O5bhRnC-DfG",
        "outputId": "1e718a4e-089b-4c1b-9d1a-39b9360f36cf"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'is_malicious': True,\n",
              " 'confidence': 0.7882174253463745,\n",
              " 'attack_type': 'xss',\n",
              " 'attack_confidence': 0.9999486207962036}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdO267cK_sf-",
        "outputId": "532ee7d1-816f-4d4e-b0b8-104bcfebf10a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'is_malicious': False,\n",
              "  'confidence': 0.12550747394561768,\n",
              "  'attack_type': None,\n",
              "  'attack_confidence': None},\n",
              " {'is_malicious': False,\n",
              "  'confidence': 0.13454963266849518,\n",
              "  'attack_type': None,\n",
              "  'attack_confidence': None},\n",
              " {'is_malicious': False,\n",
              "  'confidence': 0.13089822232723236,\n",
              "  'attack_type': None,\n",
              "  'attack_confidence': None}]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtering pipeline"
      ],
      "metadata": {
        "id": "tfZXYx0UAtTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Rule-based injection detection filter using libinjection and custom patterns\n",
        "Returns: 0 (benign), 1 (attack), 2 (ambiguous - needs model)\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "import string\n",
        "from typing import Union\n",
        "\n",
        "# Install required library: pip install libinjection-python\n",
        "try:\n",
        "    import libinjection\n",
        "    LIBINJECTION_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"Warning: libinjection-python not installed. Install with: pip install libinjection-python\")\n",
        "    LIBINJECTION_AVAILABLE = False\n",
        "\n",
        "class RuleBasedInjectionFilter:\n",
        "    \"\"\"\n",
        "    Fast rule-based filter for web injection detection\n",
        "    Uses libinjection for definitive attack detection and custom patterns for benign detection\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Compile regex patterns for performance\n",
        "        self._compile_patterns()\n",
        "\n",
        "    def _compile_patterns(self):\n",
        "        \"\"\"Compile all regex patterns for better performance\"\"\"\n",
        "\n",
        "        # Obviously benign patterns (return 0)\n",
        "        self.benign_patterns = [\n",
        "            # Pure alphanumeric\n",
        "            re.compile(r'^[a-zA-Z0-9_\\-\\.@\\s]*$'),\n",
        "\n",
        "            # Common usernames/emails\n",
        "            re.compile(r'^[a-zA-Z0-9][a-zA-Z0-9_\\-\\.]{1,63}@[a-zA-Z0-9][a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,}$'),\n",
        "\n",
        "            # Simple numeric values\n",
        "            re.compile(r'^\\d+(\\.\\d+)?$'),\n",
        "\n",
        "            # Common search terms (letters, numbers, spaces, basic punctuation)\n",
        "            re.compile(r'^[a-zA-Z0-9\\s\\'\\\"\\,\\.\\!\\?\\-]+$'),\n",
        "\n",
        "            # URL-safe strings\n",
        "            re.compile(r'^[a-zA-Z0-9\\-\\._~:/?#[\\]@!$&\\'()*+,;=]*$'),\n",
        "        ]\n",
        "\n",
        "        # Obviously malicious patterns (return 1) - High confidence\n",
        "        self.malicious_patterns = [\n",
        "            # SQL injection keywords (high confidence)\n",
        "            re.compile(r'\\b(union\\s+select|drop\\s+table|delete\\s+from|insert\\s+into)\\b', re.IGNORECASE),\n",
        "\n",
        "            # XSS script tags\n",
        "            re.compile(r'<script[^>]*>.*?</script>', re.IGNORECASE | re.DOTALL),\n",
        "            re.compile(r'<iframe[^>]*>.*?</iframe>', re.IGNORECASE | re.DOTALL),\n",
        "\n",
        "            # JavaScript execution\n",
        "            re.compile(r'javascript\\s*:', re.IGNORECASE),\n",
        "            re.compile(r'on(load|error|click|mouseover)\\s*=', re.IGNORECASE),\n",
        "\n",
        "            # Command injection\n",
        "            re.compile(r'\\b(cmd|system|exec|eval|passthru)\\s*\\(', re.IGNORECASE),\n",
        "\n",
        "            # Path traversal\n",
        "            re.compile(r'\\.\\.[\\\\/]\\.\\.[\\\\/]'),\n",
        "\n",
        "            # SQL comment patterns\n",
        "            re.compile(r'--\\s*$', re.MULTILINE),\n",
        "            re.compile(r'/\\*.*?\\*/', re.DOTALL),\n",
        "        ]\n",
        "\n",
        "        # Suspicious patterns that need model evaluation (return 2)\n",
        "        self.suspicious_patterns = [\n",
        "            # SQL-like patterns (lower confidence)\n",
        "            re.compile(r'\\b(select|from|where|order\\s+by|group\\s+by)\\b', re.IGNORECASE),\n",
        "\n",
        "            # HTML-like patterns\n",
        "            re.compile(r'<[^>]+>'),\n",
        "\n",
        "            # Encoding patterns\n",
        "            re.compile(r'%[0-9a-f]{2}', re.IGNORECASE),\n",
        "            re.compile(r'&#\\d+;'),\n",
        "\n",
        "            # Function call patterns\n",
        "            re.compile(r'\\w+\\s*\\([^)]*\\)'),\n",
        "\n",
        "            # Suspicious characters clustering\n",
        "            re.compile(r'[<>\"\\'\\(\\);=%&\\|]{3,}'),\n",
        "        ]\n",
        "\n",
        "    def is_obviously_benign(self, text: str) -> bool:\n",
        "        \"\"\"Check if text matches obviously benign patterns\"\"\"\n",
        "\n",
        "        # Empty or very short strings are usually benign\n",
        "        if not text or len(text.strip()) <= 2:\n",
        "            return True\n",
        "\n",
        "        # Check basic characteristics\n",
        "        if self._is_simple_alphanumeric(text):\n",
        "            return True\n",
        "\n",
        "        # Check against benign patterns\n",
        "        for pattern in self.benign_patterns:\n",
        "            if pattern.match(text.strip()):\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def _is_simple_alphanumeric(self, text: str) -> bool:\n",
        "        \"\"\"Check if text is simple alphanumeric with minimal special chars\"\"\"\n",
        "\n",
        "        # Count character types\n",
        "        alpha_count = sum(1 for c in text if c.isalpha())\n",
        "        digit_count = sum(1 for c in text if c.isdigit())\n",
        "        space_count = sum(1 for c in text if c.isspace())\n",
        "        safe_special = sum(1 for c in text if c in '_-.@')\n",
        "        other_count = len(text) - alpha_count - digit_count - space_count - safe_special\n",
        "\n",
        "        # If mostly alphanumeric with minimal special characters\n",
        "        total_safe = alpha_count + digit_count + space_count + safe_special\n",
        "        return len(text) > 0 and (total_safe / len(text)) >= 0.95\n",
        "\n",
        "    def has_definitive_attack(self, text: str) -> bool:\n",
        "        \"\"\"Check for definitive attack patterns using libinjection and high-confidence patterns\"\"\"\n",
        "\n",
        "        # Use libinjection for SQL injection detection\n",
        "        if LIBINJECTION_AVAILABLE:\n",
        "            try:\n",
        "                # Check SQL injection\n",
        "                sqli_result = libinjection.is_sql_injection(text)\n",
        "                if sqli_result.get('is_sqli', False):\n",
        "                    return True\n",
        "\n",
        "                # Check XSS\n",
        "                xss_result = libinjection.is_xss(text)\n",
        "                if xss_result.get('is_xss', False):\n",
        "                    return True\n",
        "            except:\n",
        "                pass  # Fall back to pattern matching if libinjection fails\n",
        "\n",
        "        # Check high-confidence malicious patterns\n",
        "        for pattern in self.malicious_patterns:\n",
        "            if pattern.search(text):\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def has_suspicious_patterns(self, text: str) -> bool:\n",
        "        \"\"\"Check for suspicious patterns that need model evaluation\"\"\"\n",
        "\n",
        "        for pattern in self.suspicious_patterns:\n",
        "            if pattern.search(text):\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def classify_text(self, text: str) -> int:\n",
        "        \"\"\"\n",
        "        Main classification function\n",
        "\n",
        "        Returns:\n",
        "            0: Obviously benign (safe to pass)\n",
        "            1: Obviously malicious (block immediately)\n",
        "            2: Ambiguous (needs model evaluation)\n",
        "        \"\"\"\n",
        "\n",
        "        if not isinstance(text, str):\n",
        "            return 2  # Non-string input needs evaluation\n",
        "\n",
        "        # Basic preprocessing\n",
        "        text = text.strip()\n",
        "\n",
        "        # Empty strings are benign\n",
        "        if not text:\n",
        "            return 0\n",
        "\n",
        "        # Check for obvious attacks first (highest priority)\n",
        "        if self.has_definitive_attack(text):\n",
        "            return 1\n",
        "\n",
        "        # Check for obviously benign patterns\n",
        "        if self.is_obviously_benign(text):\n",
        "            return 0\n",
        "\n",
        "        # Check for suspicious patterns\n",
        "        if self.has_suspicious_patterns(text):\n",
        "            return 2\n",
        "\n",
        "        # If no patterns match but not obviously benign, be cautious\n",
        "        # Check text characteristics\n",
        "        if self._needs_model_evaluation(text):\n",
        "            return 2\n",
        "\n",
        "        # Default to benign for simple text\n",
        "        return 0\n",
        "\n",
        "    def _needs_model_evaluation(self, text: str) -> bool:\n",
        "        \"\"\"Determine if text characteristics suggest model evaluation is needed\"\"\"\n",
        "\n",
        "        # Very long strings might hide attacks\n",
        "        if len(text) > 1000:\n",
        "            return True\n",
        "\n",
        "        # High ratio of special characters\n",
        "        special_chars = sum(1 for c in text if not c.isalnum() and not c.isspace())\n",
        "        if len(text) > 0 and (special_chars / len(text)) > 0.3:\n",
        "            return True\n",
        "\n",
        "        # Contains multiple encoding types\n",
        "        has_url_encoding = '%' in text\n",
        "        has_html_encoding = '&' in text and ';' in text\n",
        "        has_unicode = any(ord(c) > 127 for c in text)\n",
        "\n",
        "        encoding_count = sum([has_url_encoding, has_html_encoding, has_unicode])\n",
        "        if encoding_count >= 2:\n",
        "            return True\n",
        "\n",
        "        # Contains mixed quotes and brackets (potential injection)\n",
        "        quote_bracket_chars = sum(1 for c in text if c in '\\'\"()[]{}')\n",
        "        if quote_bracket_chars >= 4:\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "# Convenience function for direct use\n",
        "def quick_injection_check(text: str) -> int:\n",
        "    \"\"\"\n",
        "    Quick injection detection function\n",
        "\n",
        "    Args:\n",
        "        text: Input text to check\n",
        "\n",
        "    Returns:\n",
        "        0: Obviously benign (safe to pass)\n",
        "        1: Obviously malicious (block immediately)\n",
        "        2: Ambiguous (needs model evaluation)\n",
        "    \"\"\"\n",
        "    filter_instance = RuleBasedInjectionFilter()\n",
        "    return filter_instance.classify_text(text)\n",
        "\n"
      ],
      "metadata": {
        "id": "9UilO_5tAyAx"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage and testing\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Initialize filter\n",
        "    injection_filter = RuleBasedInjectionFilter()\n",
        "\n",
        "    # Test cases\n",
        "    test_cases = [\n",
        "        # Obviously benign (should return 0)\n",
        "        (\"john_smith\", 0),\n",
        "        (\"user@example.com\", 0),\n",
        "        (\"hello world tout le monde! j'espere que vous allez bien ? (bien)\", 0),\n",
        "        (\"12345\", 0),\n",
        "        (\"search term here\", 0),\n",
        "\n",
        "        # Obviously malicious (should return 1)\n",
        "        (\"'; DROP TABLE users; --\", 1),\n",
        "        (\"UNION SELECT password FROM users\", 1),\n",
        "        (\"<script>alert('xss')</script>\", 1),\n",
        "        (\"javascript:alert(1)\", 1),\n",
        "        (\"../../etc/passwd\", 1),\n",
        "\n",
        "        # Ambiguous (should return 2)\n",
        "        (\"SELECT name FROM products WHERE id=1\", 2),\n",
        "        (\"<div>content</div>\", 2),\n",
        "        (\"value=%27test%27\", 2),\n",
        "        (\"function(param)\", 2),\n",
        "    ]\n",
        "\n",
        "    print(\"Testing Rule-Based Injection Filter\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    for text, expected in test_cases:\n",
        "        result = injection_filter.classify_text(text)\n",
        "        status = \"✓\" if result == expected else \"✗\"\n",
        "\n",
        "        result_map = {0: \"BENIGN\", 1: \"ATTACK\", 2: \"AMBIGUOUS\"}\n",
        "        print(f\"{status} '{text}' -> {result} ({result_map[result]})\")\n",
        "\n",
        "    print(\"\\nLibinjection available:\", LIBINJECTION_AVAILABLE)\n",
        "\n",
        "    # Performance test\n",
        "    if LIBINJECTION_AVAILABLE:\n",
        "        import time\n",
        "\n",
        "        test_text = \"normal user input text here\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        for _ in range(1000):\n",
        "            injection_filter.classify_text(test_text)\n",
        "\n",
        "        end_time = time.time()\n",
        "        avg_time = (end_time - start_time) / 1000 * 1000  # Convert to milliseconds\n",
        "\n",
        "        print(f\"\\nAverage processing time: {avg_time:.3f} ms per request\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSXnMuBbBfmd",
        "outputId": "a537547a-df64-410a-a9b0-8f404ebdcad6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Rule-Based Injection Filter\n",
            "==================================================\n",
            "✓ 'john_smith' -> 0 (BENIGN)\n",
            "✓ 'user@example.com' -> 0 (BENIGN)\n",
            "✓ 'hello world tout le monde! j'espere que vous allez bien ? (bien)' -> 0 (BENIGN)\n",
            "✓ '12345' -> 0 (BENIGN)\n",
            "✓ 'search term here' -> 0 (BENIGN)\n",
            "✓ ''; DROP TABLE users; --' -> 1 (ATTACK)\n",
            "✓ 'UNION SELECT password FROM users' -> 1 (ATTACK)\n",
            "✓ '<script>alert('xss')</script>' -> 1 (ATTACK)\n",
            "✓ 'javascript:alert(1)' -> 1 (ATTACK)\n",
            "✓ '../../etc/passwd' -> 1 (ATTACK)\n",
            "✗ 'SELECT name FROM products WHERE id=1' -> 1 (ATTACK)\n",
            "✓ '<div>content</div>' -> 2 (AMBIGUOUS)\n",
            "✓ 'value=%27test%27' -> 2 (AMBIGUOUS)\n",
            "✗ 'function(param)' -> 0 (BENIGN)\n",
            "\n",
            "Libinjection available: True\n",
            "\n",
            "Average processing time: 0.017 ms per request\n"
          ]
        }
      ]
    }
  ]
}